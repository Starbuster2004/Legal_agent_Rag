# Legal RAG (Retrieval-Augmented Generation) â€” Hugging Face + Groq

This is a Legal RAG system with **separate user and admin interfaces** using **Hugging Face models** for embeddings and reranking (running locally) and **Groq** for final answer generation.

## ðŸš€ Quick Start

### Installation
```powershell
pip install -r requirements.txt
```

### Running the Application

#### Option A: Streamlit Only (Standalone)
```powershell
# Clear old database if upgrading
python clear_database.py

# Run Streamlit app
streamlit run app.py
```

#### Option B: FastAPI Backend + Streamlit Frontend
```powershell
# Start both servers with one command
.\start_all.ps1

# OR start individually:
.\start_backend.ps1   # FastAPI backend on port 8000
.\start_frontend.ps1  # Streamlit frontend on port 8501
```

### Access Points
- **Streamlit Home:** http://localhost:8501
- **ðŸ’¬ Chat Page:** http://localhost:8501/1_ðŸ’¬_Chat
- **ðŸ” Admin Panel:** http://localhost:8501/2_ðŸ”_Admin (password: `admin123`)
- **FastAPI Backend:** http://localhost:8000
- **API Docs:** http://localhost:8000/docs

## ðŸ“ Project Structure

### Frontend (Streamlit)
```
app.py                           # Home page
pages/
â”œâ”€â”€ 1_ðŸ’¬_Chat.py                # Public chat interface
â””â”€â”€ 2_ðŸ”_Admin.py               # Admin panel
```

### Backend (FastAPI) - NEW!
```
backend/
â”œâ”€â”€ main.py                      # FastAPI application
â”œâ”€â”€ auth.py                      # JWT authentication
â”œâ”€â”€ schemas.py                   # Pydantic models
â””â”€â”€ routes/
    â”œâ”€â”€ auth.py                  # Authentication endpoints
    â”œâ”€â”€ documents.py             # Document management
    â””â”€â”€ chat.py                  # Chat/RAG endpoints
```

### Core Components
```
config.py                        # Configuration
db_store.py                      # ChromaDB operations
pipeline.py                      # RAG pipeline
embeddings.py                    # HuggingFace models
retriever.py                     # Retrieval & reranking
llm.py                          # Groq LLM integration
```

### Database Structure
- Each document gets its **own ChromaDB collection**
- Collections are named after sanitized filenames
- Easy to manage, delete, and track individual documents
- Queries search across **all collections** automatically

### Utilities
```
start_backend.ps1               # Start FastAPI server
start_frontend.ps1              # Start Streamlit UI
start_all.ps1                   # Start both servers
clear_database.py               # Reset database
postman_collection.json         # API testing collection
```

## âœ¨ Key Features

### User Interface (ðŸ’¬ Chat)
- âœ… **No login required** - Public access to chat
- âœ… **Conversational AI** - Maintains chat history
- âœ… **Multi-document search** - Searches all indexed documents
- âœ… **Source citations** - Shows which document the answer came from
- âœ… **Clean UI** - Styled chat bubbles with scroll

### Admin Interface (ðŸ” Admin)
- âœ… **Password protected** - Secure document management
- âœ… **Bulk upload** - Upload multiple PDFs at once
- âœ… **Automatic indexing** - No manual button clicks needed
- âœ… **Document deletion** - Remove documents from database
- âœ… **Statistics dashboard** - View system metrics

### ChromaDB Structure
- âœ… **Per-document collections** - Each PDF gets its own collection
- âœ… **Easy management** - Delete individual documents without affecting others
- âœ… **Source tracking** - Full metadata with filenames and chunk info
- âœ… **Cross-collection search** - RAG searches all documents automatically

## ðŸ¤— Technology Stack

### Hugging Face Models (Local)
- **Embedding**: `sentence-transformers/all-MiniLM-L6-v2`
- **Reranking**: `cross-encoder/ms-marco-MiniLM-L-6-v2`
- **Privacy-focused** - All document processing happens locally

### Groq LLM (API)
- **Model**: Llama 3.3 70B Versatile
- **Ultra-fast inference** - 2048 token responses
- **Only used for final answers** - Not for retrieval/reranking

### ChromaDB
- **Vector database** - Persistent storage
- **Collection-per-document** - Better organization
- **Full metadata** - Track source files and chunks

### FastAPI Backend (NEW!)
- **RESTful API** - Standard HTTP endpoints
- **JWT Authentication** - Secure admin access
- **Swagger/OpenAPI** - Auto-generated documentation
- **CORS enabled** - Frontend-backend separation
- **Async operations** - Better performance

---

## ðŸ”Œ API Integration

The system now includes a **FastAPI backend** that can be used independently:

### API Features
âœ… **Authentication:** JWT-based login system
âœ… **Document Upload:** Single or bulk PDF upload
âœ… **Document Management:** List and delete documents
âœ… **Chat API:** Query documents via REST
âœ… **Health Checks:** Monitor system status
âœ… **OpenAPI Docs:** Interactive API documentation

### Example API Usage

#### 1. Login
```bash
curl -X POST http://localhost:8000/auth/login \
  -H "Content-Type: application/json" \
  -d '{"password":"admin123"}'
```

#### 2. Upload Document
```bash
curl -X POST http://localhost:8000/documents/upload \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@contract.pdf"
```

#### 3. Query Chat
```bash
curl -X POST http://localhost:8000/chat/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the key terms?","top_k":5}'
```

### Documentation
- **Full API Docs:** See [BACKEND_API.md](BACKEND_API.md)
- **Postman Collection:** Import `postman_collection.json`
- **Interactive Docs:** http://localhost:8000/docs

## âš™ï¸ Configuration

### Environment Variables (Optional)
```powershell
$env:GROQ_API_KEY="your-groq-api-key"
$env:ADMIN_PASSWORD="your-secure-password"
$env:CHROMA_DIR="./chromadb_persist"
```

### Default Admin Password
**Default:** `admin123`
**Change in:** `config.py` or set `ADMIN_PASSWORD` environment variable

---

## ðŸ—‚ï¸ Quick steps to run locally (Windows PowerShell):

1. Create & activate a virtual environment (you already created `.venv`):

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

2. Install dependencies for the backend (from the `backend/requirements.txt`):

```powershell
pip install -r .\backend\requirements.txt
pip install streamlit requests
```

3. Start the FastAPI backend:

```powershell
# from repository root
uvicorn backend.app:app --host 0.0.0.0 --port 8000 --reload
```

4. Start the Streamlit test UI (in another terminal):

```powershell
streamlit run .\streamlit_test_ui.py
```

Configuration
- Use environment variables or edit `backend/config.py` defaults:
  - `OPENROUTER_API_KEY` â€” OpenRouter API key
  - `CHROMA_PERSIST_DIR` â€” ChromaDB persistent directory
  - `ADMIN_PASSWORD` â€” Admin password for the simple JWT flow

Notes & caveats
- This is an initial scaffold implementing the core RAG pipeline and an integration test UI.
- The LLM integration calls the OpenRouter-compatible `/chat/completions` endpoint. Set `OPENROUTER_API_KEY`.
- The admin authentication is intentionally simple (password -> signed token). For production, use a proper user store and TLS.

Next steps you can ask me to do:
- Harden input validation and error handling
- Add unit tests for document processing & vector store
- Improve query relevance classifier (LLM-based)
- Implement frontend React/Tailwind UI
